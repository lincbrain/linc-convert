"""
JPEG2000 to OME-ZARR
====================

This script converts JPEG2000 files generated by MBF-Neurolucida into
a pyramidal OME-ZARR hierarchy. It does not recompute the image pyramid
but instead reuse the JPEG2000 levels (obtained by wavelet transform).

usage:
    python jp2_to_zarr.py <input_path.jp2> <output_path.ome.zarr> [options...]

options:
    --chunk INT                        Output chunk size. Default: 1024
    --compressor {blosc, zlib, raw}    Compression method. Default: blosc
    --compressor-opt DICT              Compression options.
    --max-load INT                     Maximum input chunk size. Default: 16384

dependencies:
    glymur
    zarr
    numpy
"""
import glymur
import zarr
import argparse
import ast
import numcodecs
import uuid
import os
import math
import numpy as np


def ceildiv(x, y):
    return int(math.ceil(x / y))


class WrappedJ2K:
    """
    A wrapper around the J2K object at any resolution level, and
    with virtual transposition of the axes into [C, H, W] order.

    The resulting object can be sliced, but each index must be a `slice`
    (dropping axes using integer indices or adding axes using `None`
    indices is forbidden).

    The point is to ensure that the zarr writer only loads chunk-sized data.
    """

    def __init__(self, j2k, level=0, channel_first=True):
        """
        Parameters
        ----------
        j2k : glymur.Jp2k
            The JPEG2000 object.
        level : int
            Resolution level to map (highest resolution = 0).
        channel_first : bool
            Return an array with shape (C, H, W) instead of (H, W, C)
            when there is a channel dimension.
        """
        self.j2k = j2k
        self.level = level
        self.channel_first = channel_first

    @property
    def shape(self):
        channel = list(self.j2k.shape[2:])
        shape = [ceildiv(s, 2**self.level) for s in self.j2k.shape[:2]]
        if self.channel_first:
            shape = channel + shape
        else:
            shape += channel
        return tuple(shape)

    @property
    def dtype(self):
        return self.j2k.dtype

    def __getitem__(self, index):
        if not isinstance(index, tuple):
            index = (index,)
        if Ellipsis not in index:
            index += (Ellipsis,)
        if any(idx is None for idx in index):
            raise TypeError('newaxis not supported')

        # substitute ellipses
        new_index = []
        has_seen_ellipsis = False
        last_was_ellipsis = False
        nb_ellipsis = max(0, self.j2k.ndim + 1 - len(index))
        for idx in index:
            if idx is Ellipsis:
                if not has_seen_ellipsis:
                    new_index += [slice(None)] * nb_ellipsis
                elif not last_was_ellipsis:
                    raise ValueError('Multiple ellipses should be contiguous')
                has_seen_ellipsis = True
                last_was_ellipsis = True
            elif not isinstance(idx, slice):
                raise TypeError('Only slices are supported')
            elif idx.step not in (None, 1):
                raise ValueError('Striding not supported')
            else:
                last_was_ellipsis = False
                new_index += [idx]
        index = new_index

        if self.channel_first:
            *cidx, hidx, widx = index
        else:
            hidx, widx, *cidx = index
        hstart, hstop = hidx.start or 0, hidx.stop or 0
        wstart, wstop = widx.start or 0, widx.stop or 0

        # convert to level 0 indices
        hstart *= 2**self.level
        hstop *= 2**self.level
        wstart *= 2**self.level
        wstop *= 2**self.level
        hstop = min(hstop or self.j2k.shape[0], self.j2k.shape[0])
        wstop = min(wstop or self.j2k.shape[1], self.j2k.shape[1])
        area = (hstart, wstart, hstop, wstop)

        data = self.j2k.read(rlevel=self.level, area=area)
        if cidx:
            data = data[:, :, cidx[0]]
            if self.channel_first:
                data = np.transpose(data, [2, 0, 1])
        return data


def make_compressor(name, **prm):
    if not isinstance(name, str):
        return name
    name = name.lower()
    if name == 'blosc':
        Compressor = numcodecs.Blosc
    elif name == 'zlib':
        Compressor = numcodecs.Zlib
    else:
        raise ValueError('Unknown compressor', name)
    return Compressor(**prm)


def get_pixelsize(j2k):
    # Adobe XMP metadata
    # https://en.wikipedia.org/wiki/Extensible_Metadata_Platform
    XMP_UUID = 'BE7ACFCB97A942E89C71999491E3AFAC'
    TAG_Images = '{http://ns.adobe.com/xap/1.0/}Images'
    Tag_Desc = '{http://www.w3.org/1999/02/22-rdf-syntax-ns#}Description'
    Tag_PixelWidth = '{http://ns.adobe.com/xap/1.0/}PixelWidth'
    Tag_PixelHeight = '{http://ns.adobe.com/xap/1.0/}PixelHeight'

    vxw = vxh = 1.0
    for box in j2k.box:
        if getattr(box, 'uuid', None) == uuid.UUID(XMP_UUID):
            try:
                images = list(box.data.iter(TAG_Images))[0]
                desc = list(images.iter(Tag_Desc))[0]
                vxw = float(desc.attrib[Tag_PixelWidth])
                vxh = float(desc.attrib[Tag_PixelHeight])
            except Exception:
                pass
    return vxw, vxh


def convert(inp, out, chunk=1024, compressor='blosc', compressor_opt={},
            max_load=16384):

    j2k = glymur.Jp2k(inp)
    vxw, vxh = get_pixelsize(j2k)

    # Prepare Zarr group
    omz = zarr.storage.DirectoryStore(out)
    omz = zarr.group(store=omz, overwrite=False)

    # Prepare chunking options
    opt = {
        'chunks': list(j2k.shape[2:]) + [chunk, chunk],
        'dimension_separator': r'/',
        'order': 'F',
        'dtype': np.dtype(j2k.dtype).str,
        'fill_value': None,
        'compressor': make_compressor(compressor, **compressor_opt),
    }

    # Write each level
    nblevel = j2k.codestream.segment[2].num_res
    has_channel = j2k.ndim - 2
    for level in range(nblevel):
        # subdat = j2k[::2**level, ::2**level, ...]
        # subdat = np.transpose(subdat, [-1] * has_channel + [0, 1])
        subdat = WrappedJ2K(j2k, level=level)
        shape = subdat.shape
        print('Convert level', level, 'with shape', shape)
        omz.create_dataset(str(level), shape=shape, **opt)
        array = omz[str(level)]
        if max_load is None or (shape[-2] < max_load and shape[-1] < max_load):
            array[...] = subdat[...]
        else:
            ni = ceildiv(shape[-2], max_load)
            nj = ceildiv(shape[-1], max_load)
            for i in range(ni):
                for j in range(nj):
                    print(f'\r{i+1}/{ni}, {j+1}/{nj}', end='')
                    array[
                        ...,
                        i*max_load:min((i+1)*max_load, shape[-2]),
                        j*max_load:min((j+1)*max_load, shape[-1]),
                    ] = subdat[
                        ...,
                        i*max_load:min((i+1)*max_load, shape[-2]),
                        j*max_load:min((j+1)*max_load, shape[-1]),
                    ]
            print('')

    # Write OME-Zarr multiscale metadata
    print('Write metadata')
    multiscales = [{
        'version': '0.4',
        'axes': [
            {"name": "y", "type": "space", "unit": "micrometer"},
            {"name": "x", "type": "space", "unit": "micrometer"}
        ],
        'datasets': [],
        'type': 'jpeg2000',
        'name': '',
    }]
    if has_channel:
        multiscales[0]['axes'].insert(0, {"name": "c", "type": "channel"})

    for n in range(nblevel):
        shape0 = omz['0'].shape[-2:]
        shape = omz[str(n)].shape[-2:]
        multiscales[0]['datasets'].append({})
        level = multiscales[0]['datasets'][-1]
        level["path"] = str(n)

        # I assume that wavelet transforms end up aligning voxel edges
        # across levels, so the effective scaling is the shape ratio,
        # and there is a half voxel shift wrt to the "center of first voxel"
        # frame
        level["coordinateTransformations"] = [
            {
                "type": "scale",
                "scale": [1.0] * has_channel + [
                    (shape0[0]/shape[0])*vxh,
                    (shape0[1]/shape[1])*vxw,
                ]
            },
            {
                "type": "translation",
                "translation": [0.0] * has_channel + [
                    (shape0[0]/shape[0] - 1)*vxh*0.5,
                    (shape0[1]/shape[1] - 1)*vxw*0.5,
                ]
            }
        ]
    multiscales[0]["coordinateTransformations"] = [
        {
            "scale": [1.0] * (2 + has_channel),
            "type": "scale"
        }
    ]
    omz.attrs["multiscales"] = multiscales
    print('done.')


if __name__ == "__main__":

    parser = argparse.ArgumentParser()
    parser.add_argument(
        dest='inp', help='Input JPEG2000 file')
    parser.add_argument(
        dest='out', nargs='?', default=None, help='Output OME-ZARR file')
    parser.add_argument(
        '--chunk', type=int, default=1024, help='Chunk size')
    parser.add_argument(
        '--compressor', choices=('blosc', 'zlib', 'raw'), default='blosc',
        help='Compressor')
    parser.add_argument(
        '--compressor-opt', default='{}', help='Dictionary of options')
    parser.add_argument(
        '--max-load', type=int, default=16384,
        help='Maximum patch shape to load in memory')
    args = parser.parse_args()

    out = args.out
    if not out:
        out = os.path.splitext(args.inp)[0] + '.ome.zarr'

    convert(
        args.inp, out,
        chunk=args.chunk,
        compressor=args.compressor,
        compressor_opt=ast.literal_eval(args.compressor_opt),
        max_load=args.max_load,
    )
