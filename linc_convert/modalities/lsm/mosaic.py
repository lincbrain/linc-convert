"""
Convert a collection of tiff files generated by the LSM pipeline into a Zarr.

Example input files can be found at
https://lincbrain.org/dandiset/000004/0.240319.1924/files?location=derivatives%2F
"""

# stdlib
import ast
import os
import re
from glob import glob
from typing import Literal

# externals
import cyclopts
import tensorstore as ts
from tifffile import TiffFile

# internals
from linc_convert.modalities.lsm.cli import lsm
from linc_convert.utils.orientation import center_affine, orientation_to_affine
from linc_convert.utils.zarr import (
    default_write_config,
    generate_pyramid,
    niftizarr_write_header,
    write_ome_metadata,
)

mosaic = cyclopts.App(name="mosaic", help_format="markdown")
lsm.command(mosaic)


@mosaic.default
def convert(
    inp: str,
    out: str = None,
    *,
    chunk: list[int] = [128],
    shard: list[int | str] | None = None,
    zarr_version: Literal[2, 3] = 3,
    compressor: str = "blosc",
    compressor_opt: str = "{}",
    max_load: int = 512,
    nii: bool = False,
    orientation: str = "coronal",
    center: bool = True,
    voxel_size: list[float] = (1, 1, 1),
) -> None:
    """
    Convert a collection of tiff files generated by the LSM pipeline into ZARR.

    Orientation
    -----------
    The anatomical orientation of the slice is given in terms of RAS axes.

    It is a combination of two letters from the set
    `{"L", "R", "A", "P", "I", "S"}`, where

    * the first letter corresponds to the horizontal dimension and
        indicates the anatomical meaning of the _right_ of the image,
    * the second letter corresponds to the vertical dimension and
        indicates the anatomical meaning of the _bottom_ of the image.

    We also provide the aliases

    * `"coronal"` == `"LI"`
    * `"axial"` == `"LP"`
    * `"sagittal"` == `"PI"`

    The orientation flag is only useful when converting to nifti-zarr.

    Parameters
    ----------
    inp
        Path to the root directory, which contains a collection of
        subfolders named `*_z{:02d}_y{:02d}*`, each containing a
        collection of files named `*_plane{:03d}_c{:d}.tiff`.
    out
        Path to the output Zarr directory [<INP>.ome.zarr]
    chunk
        Output chunk size.
        Behavior depends on the number of values provided:
        * one:   used for all spatial dimensions
        * three: used for spatial dimensions ([z, y, x])
        * four:  used for channels and spatial dimensions ([c, z, y, x])
    shard
        Output shard size.
        If `"auto"`, find shard size that ensures files smaller than 2TB,
        assuming a compression ratio or 2.
    zarr_version
        Zarr version to use. If `shard` is used, 3 is required.
    compressor : {blosc, zlib|gzip, raw}
        Compression method
    compressor_opt
        Compression options
    max_load
        Maximum input chunk size when building pyramid
    nii
        Convert to nifti-zarr. True if path ends in ".nii.zarr".
    orientation
        Orientation of the slice
    center
        Set RAS[0, 0, 0] at FOV center
    voxel_size
        Voxel size along the X, Y and Z dimension, in micron.
    """
    # ------------------------------------------------------------------
    # Checks and slight reformatting
    # ------------------------------------------------------------------
    if shard == ["auto"]:
        shard = "auto"

    if isinstance(compressor_opt, str):
        compressor_opt = ast.literal_eval(compressor_opt)

    if max_load % 2:
        max_load += 1

    if zarr_version < 3 and shard:
        raise ValueError("Sharding requires zarr v3")

    # ------------------------------------------------------------------
    # Parse all input tiles and their shape
    # ------------------------------------------------------------------

    CHUNK_PATTERN = re.compile(
        r"^(?P<prefix>\w*)" r"_z(?P<z>[0-9]+)" r"_y(?P<y>[0-9]+)" r"(?P<suffix>\w*)$"
    )

    all_chunks_dirnames = list(sorted(glob(os.path.join(inp, "*_z*_y*"))))
    all_chunks_info = dict(
        dirname=[],
        prefix=[],
        suffix=[],
        z=[],
        y=[],
        planes=[
            dict(
                fname=[],
                z=[],
                c=[],
                yx_shape=[],
            )
            for _ in range(len(all_chunks_dirnames))
        ],
    )

    # parse all directory names
    for dirname in all_chunks_dirnames:
        parsed = CHUNK_PATTERN.fullmatch(os.path.basename(dirname))
        all_chunks_info["dirname"].append(dirname)
        all_chunks_info["prefix"].append(parsed.group("prefix"))
        all_chunks_info["suffix"].append(parsed.group("suffix"))
        all_chunks_info["z"].append(int(parsed.group("z")))
        all_chunks_info["y"].append(int(parsed.group("y")))

    # default output name
    if not out:
        out = all_chunks_info["prefix"][0] + all_chunks_info["suffix"][0]
        out += ".nii.zarr" if nii else ".ome.zarr"
    nii = nii or out.endswith(".nii.zarr")

    # parse all individual file names
    nchunkz = max(all_chunks_info["z"])
    nchunky = max(all_chunks_info["y"])
    allshapes = [[(0, 0, 0) for _ in range(nchunky)] for _ in range(nchunkz)]
    nchannels = 0
    dtype = None
    for zchunk in range(nchunkz):
        for ychunk in range(nchunky):
            for i in range(len(all_chunks_info["dirname"])):
                if (
                    all_chunks_info["z"][i] == zchunk + 1
                    and all_chunks_info["y"][i] == ychunk + 1
                ):
                    break
            dirname = all_chunks_info["dirname"][i]
            planes_filenames = list(sorted(glob(os.path.join(dirname, "*.tiff"))))

            PLANE_PATTERN = re.compile(
                os.path.basename(dirname) + r"_plane(?P<z>[0-9]+)"
                r"_c(?P<c>[0-9]+)"
                r".tiff$"
            )

            for fname in planes_filenames:
                parsed = PLANE_PATTERN.fullmatch(os.path.basename(fname))
                all_chunks_info["planes"][i]["fname"] += [fname]
                all_chunks_info["planes"][i]["z"] += [int(parsed.group("z"))]
                all_chunks_info["planes"][i]["c"] += [int(parsed.group("c"))]

                f = TiffFile(fname)
                dtype = f.pages[0].dtype
                yx_shape = f.pages[0].shape
                all_chunks_info["planes"][i]["yx_shape"].append(yx_shape)

            nplanes = max(all_chunks_info["planes"][i]["z"])
            nchannels = max(nchannels, max(all_chunks_info["planes"][i]["c"]))

            yx_shape = set(all_chunks_info["planes"][i]["yx_shape"])
            if not len(yx_shape) == 1:
                raise ValueError("Incompatible chunk shapes")
            yx_shape = list(yx_shape)[0]
            allshapes[zchunk][ychunk] = (nplanes, *yx_shape)

    # check that all chunk shapes are compatible
    for zchunk in range(nchunkz):
        if len(set(shape[1] for shape in allshapes[zchunk])) != 1:
            raise ValueError("Incompatible Y shapes")
    for ychunk in range(nchunky):
        if len(set(shape[ychunk][0] for shape in allshapes)) != 1:
            raise ValueError("Incompatible Z shapes")
    if len(set(shape[2] for subshapes in allshapes for shape in subshapes)) != 1:
        raise ValueError("Incompatible X shapes")

    # compute full shape
    fullshape = [0, 0, 0]
    fullshape[0] = sum(shape[0][0] for shape in allshapes)
    fullshape[1] = sum(shape[1] for shape in allshapes[0])
    fullshape[2] = allshapes[0][0][2]

    # ------------------------------------------------------------------
    # Write into a zarr (first level)
    # ------------------------------------------------------------------

    shape = fullshape

    print("Write level 0 with shape", [nchannels, *shape])

    wconfig = default_write_config(
        path=os.path.join(out, "0"),
        shape=[nchannels, *shape],
        dtype=dtype,
        chunk=chunk,
        shard=shard,
        compressor=compressor,
        compressor_opt=compressor_opt,
        version=zarr_version,
    )
    wconfig["create"] = True
    wconfig["delete_existing"] = True

    tswriter = ts.open(wconfig).result()

    for i, dirname in enumerate(all_chunks_info["dirname"]):
        chunkz = all_chunks_info["z"][i] - 1
        chunky = all_chunks_info["y"][i] - 1
        planes = all_chunks_info["planes"][i]
        for j, fname in enumerate(planes["fname"]):
            subz = planes["z"][j] - 1
            subc = planes["c"][j] - 1
            yx_shape = planes["yx_shape"][j]

            zstart = sum(shape[0][0] for shape in allshapes[:chunkz])
            ystart = sum(
                shape[1] for subshapes in allshapes for shape in subshapes[:chunky]
            )

            print(
                f"Write plane ({subc:4d}, {zstart + subz:4d}, "
                f"{ystart:4d}:{ystart + yx_shape[0]:4d})",
                end="\r",
            )

            dat = TiffFile(fname).asarray()
            try:
                with ts.Transaction() as txn:
                    tswriter.with_transaction(txn)[
                        subc,
                        zstart + subz,
                        slice(ystart, ystart + yx_shape[0]),
                        slice(None),
                    ] = dat
            except Exception:
                print("")
                raise

    print("")

    # ------------------------------------------------------------------
    # Build pyramid using median windows
    # ------------------------------------------------------------------

    print("Generate pyramid levels")
    allshapes = generate_pyramid(
        path=out,
        shard="auto" if shard == "auto" else None,
        ndim=3,
        max_load=max_load,
    )

    # ------------------------------------------------------------------
    # Write OME-Zarr multiscale metadata
    # ------------------------------------------------------------------

    print("Write metadata")
    write_ome_metadata(
        path=out,
        axes=["c", "z", "y", "x"],
        space_scale=list(map(float, reversed(voxel_size))),
        space_unit="micrometer",
        pyramid_aligns=2,
    )

    if not nii:
        print("done.")
        return

    # ------------------------------------------------------------------
    # Write NIfTI-Zarr header
    # ------------------------------------------------------------------
    shape = list(reversed(fullshape)) + [1, nchannels]  # insert time dimension
    affine = orientation_to_affine(orientation, *voxel_size)
    if center:
        affine = center_affine(affine, shape[:3])

    niftizarr_write_header(
        out,
        shape,
        affine,
        dtype=dtype,
        unit="micron",
        zarr_version=zarr_version,
    )
    print("done.")
