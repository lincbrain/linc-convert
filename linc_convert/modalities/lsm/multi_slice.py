"""
Convert a collection of tiff files generated by the LSM pipeline into a Zarr.

Example input files can be found at
https://lincbrain.org/dandiset/000010/draft/files?location=sourcedata%2Fderivatives
"""

# stdlib
import os
import re
from glob import glob
from typing import Unpack

# externals
import cyclopts
import nibabel as nib
import numpy as np
from tifffile import TiffFile

# internals
from linc_convert.modalities.lsm.cli import lsm
from linc_convert.utils.io.zarr import from_config
from linc_convert.utils.orientation import center_affine, orientation_to_affine
from linc_convert.utils.zarr_config import ZarrConfig, update_default_config

multi_slice = cyclopts.App(name="multi_slice", help_format="markdown")
lsm.command(multi_slice)


@multi_slice.default
def convert(
    inp: str,
    *,
    zarr_config: ZarrConfig = None,
    overlap: int = 30,
    max_load: int = 512,
    orientation: str = "coronal",
    center: bool = True,
    thickness: float | None = None,
    voxel_size: list[float] = (1, 1, 1),
    **kwargs: Unpack[ZarrConfig],
) -> None:
    """
    Convert a collection of tiff files generated by the LSM pipeline into a Zarr.

    Orientation
    -----------
    The anatomical orientation of the slice is given in terms of RAS axes.

    It is a combination of two letters from the set
    `{"L", "R", "A", "P", "I", "S"}`, where

    * the first letter corresponds to the horizontal dimension and
        indicates the anatomical meaning of the _right_ of the image,
    * the second letter corresponds to the vertical dimension and
        indicates the anatomical meaning of the _bottom_ of the image.

    We also provide the aliases

    * `"coronal"` == `"LI"`
    * `"axial"` == `"LP"`
    * `"sagittal"` == `"PI"`

    The orientation flag is only useful when converting to nifti-zarr.

    Parameters
    ----------
    inp
        Path to the root directory, which contains a collection of
        files named `*_y{:02d}_z{:02d}*.tiff*`.
    out
        Path to the output Zarr directory [<INP>.{ome|nii}.zarr]
    overlap
        Number of pixels between slices that are overlapped
    chunk
        Output chunk size
    compressor : {blosc, zlib, raw}
        Compression method
    compressor_opt
        Compression options
    max_load
        Maximum input chunk size when building pyramid
    nii
        Convert to nifti-zarr. True if `out` path ends in ".nii.zarr".
    orientation
        Orientation of the slice
    center
        Set RAS[0, 0, 0] at FOV center
    voxel_size
        Voxel size along the X, Y and Z dimensions, in microns.
    """
    zarr_config = update_default_config(zarr_config, **kwargs)
    if max_load % 2:
        max_load += 1

    CHUNK_PATTERN = re.compile(
        r"^(?P<prefix>\w*)"
        r"_y(?P<y>[0-9]+)"
        r"_z(?P<z>[0-9]+)"
        r"("
        r"?P<suffix>\w*)$"
    )

    all_chunks_filenames = list(sorted(glob(os.path.join(inp, "*_y*_z*.tiff"))))
    all_chunks_info = dict(filename=[], prefix=[], suffix=[], z=[], y=[])

    # parse all directory names
    for filename in all_chunks_filenames:
        parsed = CHUNK_PATTERN.fullmatch(
            os.path.splitext(os.path.basename(filename))[0]
        )
        all_chunks_info["filename"].append(filename)
        all_chunks_info["prefix"].append(parsed.group("prefix"))
        all_chunks_info["suffix"].append(parsed.group("suffix"))
        all_chunks_info["z"].append(int(parsed.group("z")))
        all_chunks_info["y"].append(int(parsed.group("y")))

    # default output name
    zarr_config.set_default_name(
        all_chunks_info["prefix"][0] + all_chunks_info["suffix"][0]
    )

    # parse all individual file names
    nchunkz = max(all_chunks_info["z"])
    nchunky = max(all_chunks_info["y"])
    allshapes = [[(0, 0, 0) for _ in range(nchunky)] for _ in range(nchunkz)]

    dtype = None
    for zchunk in range(nchunkz):
        for ychunk in range(nchunky):
            for i in range(len(all_chunks_info["filename"])):
                if (
                    all_chunks_info["z"][i] == zchunk + 1
                    and all_chunks_info["y"][i] == ychunk + 1
                ):
                    break
            filename = all_chunks_info["filename"][i]
            f = TiffFile(filename)
            dtype = f.pages[0].dtype
            allshapes[zchunk][ychunk] = (len(f.pages), *f.pages[0].shape)

    # check that all chunk shapes are compatible
    for zchunk in range(nchunkz):
        if len(set(shape[1] for shape in allshapes[zchunk])) != 1:
            raise ValueError("Incompatible Y shapes")
    for ychunk in range(nchunky):
        if len(set(shape[ychunk][0] for shape in allshapes)) != 1:
            raise ValueError("Incompatible Z shapes")
    if len(set(shape[2] for subshapes in allshapes for shape in subshapes)) != 1:
        raise ValueError("Incompatible X shapes")

    # compute full shape
    fullshape = [0, 0, 0]
    fullshape[0] = sum(shape[0][0] for shape in allshapes)
    fullshape[1] = (
        sum(shape[1] for shape in allshapes[0])
        - (len(set(all_chunks_info["y"])) - 1) * overlap
    )
    fullshape[2] = allshapes[0][0][2]

    # Prepare Zarr group
    omz = from_config(zarr_config)
    print(zarr_config.out)

    # write first level
    array = omz.create_array(
        "0", shape=fullshape, dtype=np.dtype(dtype).str, zarr_config=zarr_config
    )

    print("Write level 0 with shape", fullshape)

    for i, filename in enumerate(all_chunks_info["filename"]):
        chunkz = all_chunks_info["z"][i] - 1
        chunky = all_chunks_info["y"][i] - 1
        f = TiffFile(filename)

        pages = f.pages
        dat = f.asarray()
        if len(set(all_chunks_info["y"])) != 1 and overlap != 0:
            if chunky != 0:
                dat = dat[:, overlap // 2:, :]
            if chunky != max(all_chunks_info["y"]) - 1:
                dat = dat[:, : -overlap // 2 - (overlap % 2), :]

        zstart = sum(shape[chunky][0] for shape in allshapes[:chunkz])
        ystart = sum(shape[1] - overlap for shape in allshapes[chunkz][:chunky])
        if chunky != 0:
            ystart += overlap // 2
        print(
            f"Write plane "
            f"( {zstart} :{zstart + len(pages)}, {ystart}:{ystart + dat.shape[1]})",
            end="\r",
        )
        slicer = (
            slice(zstart, zstart + len(pages)),
            slice(ystart, ystart + dat.shape[1]),
            slice(None),
        )
        array[slicer] = dat
    print("")
    omz.generate_pyramid(mode="mean")
    print("")

    # Write OME-Zarr multiscale metadata
    print("Write metadata")
    voxel_size = list(map(float, reversed(voxel_size)))

    omz.write_ome_metadata(["z", "y", "x"], voxel_size)

    if not zarr_config.nii:
        print("done.")
        return

    # Write NIfTI-Zarr header
    # NOTE: we use nifti2 because dimensions typically do not fit in a short
    # TODO: we do not write the json zattrs, but it should be added in
    #       once the nifti-zarr package is released
    shape = list(reversed(omz["0"].shape))
    shape = shape[:3] + [1] + shape[3:]  # insert time dimension
    affine = orientation_to_affine(orientation, *voxel_size)
    if center:
        affine = center_affine(affine, shape[:3])
    header = nib.Nifti2Header()
    header.set_data_shape(shape)
    header.set_data_dtype(omz["0"].dtype)
    header.set_qform(affine)
    header.set_sform(affine)
    header.set_xyzt_units(nib.nifti1.unit_codes.code["micron"])
    header.structarr["magic"] = b"nz2\0"
    omz.write_nifti_header(header)
    print("done.")
