"""
Convert a collection of tiff files generated by the LSM pipeline into a Zarr.

Example input files can be found at
https://lincbrain.org/dandiset/000010/draft/files?location=sourcedata%2Fderivatives
"""
import logging

# stdlib
import os
import re
from glob import glob

# externals
import cyclopts
import numpy as np
from tifffile import TiffFile

# internals
from linc_convert.modalities.lsm.cli import lsm
from linc_convert.utils.io.zarr import from_config
from linc_convert.utils.nifti_header import build_nifti_header
from linc_convert.utils.zarr_config import (
    GeneralConfig,
    NiftiConfig,
    ZarrConfig,
    autoconfig,
)

logger = logging.getLogger(__name__)
multi_slice = cyclopts.App(name="multi_slice", help_format="markdown")
lsm.command(multi_slice)


@multi_slice.default
@autoconfig
def convert(
    inp: str,
    *,
    overlap: int = 30,
    voxel_size: list[float] = (1, 1, 1),
    general_config: GeneralConfig = None,
    zarr_config: ZarrConfig = None,
    nii_config: NiftiConfig = None,
) -> None:
    """
    Convert a collection of tiff files generated by the LSM pipeline into a Zarr.
    
    Parameters
    ----------
    inp
        Path to the root directory, which contains a collection of
        files named `*_y{:02d}_z{:02d}*.tiff*`.
    overlap
        Number of pixels between slices that are overlapped
    voxel_size
        Voxel size along the X, Y and Z dimensions, in microns.
    general_config
        General configuration
    zarr_config
        Zarr related configuration
    nii_config
        NIfTI header related configuration
    """
    max_load = general_config.max_load
    if max_load % 2:
        max_load += 1

    CHUNK_PATTERN = re.compile(
        r"^(?P<prefix>\w*)"
        r"_y(?P<y>[0-9]+)"
        r"_z(?P<z>[0-9]+)"
        r"("
        r"?P<suffix>\w*)$"
    )

    all_chunks_filenames = list(sorted(glob(os.path.join(inp, "*_y*_z*.tiff"))))
    all_chunks_info = dict(filename=[], prefix=[], suffix=[], z=[], y=[])

    # parse all directory names
    for filename in all_chunks_filenames:
        parsed = CHUNK_PATTERN.fullmatch(
            os.path.splitext(os.path.basename(filename))[0]
        )
        all_chunks_info["filename"].append(filename)
        all_chunks_info["prefix"].append(parsed.group("prefix"))
        all_chunks_info["suffix"].append(parsed.group("suffix"))
        all_chunks_info["z"].append(int(parsed.group("z")))
        all_chunks_info["y"].append(int(parsed.group("y")))

    # default output name
    general_config.set_default_name(
        all_chunks_info["prefix"][0] + all_chunks_info["suffix"][0]
    )

    # parse all individual file names
    nchunkz = max(all_chunks_info["z"])
    nchunky = max(all_chunks_info["y"])
    allshapes = [[(0, 0, 0) for _ in range(nchunky)] for _ in range(nchunkz)]

    dtype = None
    for zchunk in range(nchunkz):
        for ychunk in range(nchunky):
            for i in range(len(all_chunks_info["filename"])):
                if (
                    all_chunks_info["z"][i] == zchunk + 1
                    and all_chunks_info["y"][i] == ychunk + 1
                ):
                    break
            filename = all_chunks_info["filename"][i]
            f = TiffFile(filename)
            dtype = f.pages[0].dtype
            allshapes[zchunk][ychunk] = (len(f.pages), *f.pages[0].shape)

    # check that all chunk shapes are compatible
    for zchunk in range(nchunkz):
        if len(set(shape[1] for shape in allshapes[zchunk])) != 1:
            raise ValueError("Incompatible Y shapes")
    for ychunk in range(nchunky):
        if len(set(shape[ychunk][0] for shape in allshapes)) != 1:
            raise ValueError("Incompatible Z shapes")
    if len(set(shape[2] for subshapes in allshapes for shape in subshapes)) != 1:
        raise ValueError("Incompatible X shapes")

    # compute full shape
    fullshape = [0, 0, 0]
    fullshape[0] = sum(shape[0][0] for shape in allshapes)
    fullshape[1] = (
        sum(shape[1] for shape in allshapes[0])
        - (len(set(all_chunks_info["y"])) - 1) * overlap
    )
    fullshape[2] = allshapes[0][0][2]

    # Prepare Zarr group
    omz = from_config(general_config.out, zarr_config)
    logger.info(general_config.out)

    # write first level
    array = omz.create_array(
        "0", shape=fullshape, dtype=np.dtype(dtype).str, zarr_config=zarr_config
    )

    print("Write level 0 with shape", fullshape)

    for i, filename in enumerate(all_chunks_info["filename"]):
        chunkz = all_chunks_info["z"][i] - 1
        chunky = all_chunks_info["y"][i] - 1
        f = TiffFile(filename)

        pages = f.pages
        dat = f.asarray()
        if len(set(all_chunks_info["y"])) != 1 and overlap != 0:
            if chunky != 0:
                dat = dat[:, overlap // 2:, :]
            if chunky != max(all_chunks_info["y"]) - 1:
                dat = dat[:, : -overlap // 2 - (overlap % 2), :]

        zstart = sum(shape[chunky][0] for shape in allshapes[:chunkz])
        ystart = sum(shape[1] - overlap for shape in allshapes[chunkz][:chunky])
        if chunky != 0:
            ystart += overlap // 2
        print(
            f"Write plane "
            f"( {zstart} :{zstart + len(pages)}, {ystart}:{ystart + dat.shape[1]})",
            end="\r",
        )
        slicer = (
            slice(zstart, zstart + len(pages)),
            slice(ystart, ystart + dat.shape[1]),
            slice(None),
        )
        array[slicer] = dat
    print("")
    omz.generate_pyramid(mode="mean")
    print("")

    # Write OME-Zarr multiscale metadata
    print("Write metadata")
    voxel_size = list(map(float, reversed(voxel_size)))

    omz.write_ome_metadata(["z", "y", "x"], voxel_size)

    if nii_config.nii:
        header = build_nifti_header(
            zgroup=omz,
            voxel_size_zyx=tuple(voxel_size),
            unit="micrometer",
            nii_config=nii_config,
        )
        omz.write_nifti_header(header)

    logger.info("Conversion complete.")
