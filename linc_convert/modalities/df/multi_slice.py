"""
Convert JPEG2000 files generated by MBF-Neurolucida into a OME-ZARR pyramid.

We do not recompute the image pyramid but instead reuse the JPEG2000
levels (obtained by wavelet transform).
"""

# stdlib
import json
import os

# externals
import glymur
import nibabel as nib
import numpy as np
from cyclopts import App

# internals
from linc_convert.modalities.df.cli import df
from linc_convert.utils.io.j2k import WrappedJ2K, get_pixelsize
from linc_convert.utils.math import ceildiv, floordiv
from linc_convert.utils.orientation import center_affine, orientation_to_affine
from linc_convert.utils.io.zarr import from_config
from linc_convert.utils.zarr_config import ZarrConfig, update_default_config

HOME = "/space/aspasia/2/users/linc/000003"

# Path to LincBrain dataset
LINCSET = os.path.join(HOME, "sourcedata")
LINCOUT = os.path.join(HOME, "rawdata")

ms = App(name="multislice", help_format="markdown")
df.command(ms)


@ms.default
def convert(
        inp: list[str],
        *,
        zarr_config: ZarrConfig = None,
        max_load: int = 16384,
        orientation: str = "coronal",
        center: bool = True,
        thickness: float | None = None,
        **kwargs
) -> None:
    """
    Convert JPEG2000 files generated by MBF-Neurolucida into a Zarr pyramid.

    It does not recompute the image pyramid but instead reuse the
    JPEG2000 levels (obtained by wavelet transform).

    This command converts a batch of slices and stacks them together
    into a single 3D Zarr.

    Orientation
    -----------
    The anatomical orientation of the slice is given in terms of RAS axes.

    It is a combination of two letters from the set
    `{"L", "R", "A", "P", "I", "S"}`, where

    * the first letter corresponds to the horizontal dimension and
      indicates the anatomical meaning of the _right_ of the jp2 image,
    * the second letter corresponds to the vertical dimension and
      indicates the anatomical meaning of the _bottom_ of the jp2 image,
    * the third letter corresponds to the slice dimension and
      indicates the anatomical meaninff of the _end_ of the stack.

    We also provide the aliases

    * `"coronal"` == `"LI"`
    * `"axial"` == `"LP"`
    * `"sagittal"` == `"PI"`

    The orientation flag is only useful when converting to nifti-zarr.

    Parameters
    ----------
    inp
        Path to the input slices
    max_load
        Maximum input chunk size
    orientation
        Orientation of the slice
    center
        Set RAS[0, 0, 0] at FOV center
    thickness
        Slice thickness
    """
    zarr_config = update_default_config(zarr_config, **kwargs)
    zarr_config.set_default_name(os.path.splitext(inp[0])[0])

    omz = from_config(zarr_config)

    nblevel, has_channel, dtype_jp2 = float("inf"), float("inf"), ""

    # Compute output shape
    new_height, new_width = 0, 0
    for inp1 in inp:
        jp2 = glymur.Jp2k(inp1)
        nblevel = min(nblevel, jp2.codestream.segment[2].num_res)
        has_channel = min(has_channel, jp2.ndim - 2)
        dtype_jp2 = np.dtype(jp2.dtype).str
        if jp2.shape[0] > new_height:
            new_height = jp2.shape[0]
        if jp2.shape[1] > new_width:
            new_width = jp2.shape[1]
    new_size = (new_height, new_width)
    if has_channel:
        new_size += (3,)
    print(len(inp), new_size, nblevel, has_channel)
    chunks = list(new_size[2:]) + [1] + list(zarr_config.chunk[-2:])
    zarr_config.update(chunk=tuple(chunks))
    print(new_size)
    # Write each level
    for level in range(nblevel):
        shape = [ceildiv(s, 2 ** level) for s in new_size[:2]]
        shape = [new_size[2]] + [len(inp)] + shape

        # omz.create_dataset(f"{level}", shape=shape, **opt)
        omz.create_array(str(level), shape, dtype=dtype_jp2, zarr_config=zarr_config)
        array = omz[f"{level}"]

        # Write each slice
        for idx, inp1 in enumerate(inp):
            j2k = glymur.Jp2k(inp1)
            vxw, vxh = get_pixelsize(j2k)
            subdat = WrappedJ2K(j2k, level=level)
            subdat_size = subdat.shape
            print(
                "Convert level",
                level,
                "with shape",
                shape,
                "for slice",
                idx,
                "with size",
                subdat_size,
            )

            # offset while attaching
            x = floordiv(shape[-2] - subdat_size[-2], 2)
            y = floordiv(shape[-1] - subdat_size[-1], 2)

            for channel in range(3):
                if max_load is None or (
                        subdat_size[-2] < max_load and subdat_size[-1] < max_load
                ):
                    array[
                    channel, idx, x: x + subdat_size[-2], y: y + subdat_size[-1]
                    ] = subdat[channel: channel + 1, ...][0]
                else:
                    ni = ceildiv(subdat_size[-2], max_load)
                    nj = ceildiv(subdat_size[-1], max_load)

                    for i in range(ni):
                        for j in range(nj):
                            print(f"\r{i + 1}/{ni}, {j + 1}/{nj}", end=" ")
                            start_x, end_x = (
                                i * max_load,
                                min((i + 1) * max_load, subdat_size[-2]),
                            )
                            start_y, end_y = (
                                j * max_load,
                                min((j + 1) * max_load, subdat_size[-1]),
                            )

                            array[
                            channel,
                            idx,
                            x + start_x: x + end_x,
                            y + start_y: y + end_y,
                            ] = subdat[
                                channel: channel + 1,
                                start_x:end_x,
                                start_y:end_y,
                                ][0]

                    print("")

    # Write OME-Zarr multiscale metadata
    print("Write metadata")
    axes = ["z", "y", "x"]
    if has_channel:
        axes.insert(0, "c")
    omz.write_ome_metadata(axes=axes, space_scale=[1.0] + list(get_pixelsize(j2k)),
                           multiscales_type="jpeg2000", no_pool=0)

    # Write NIfTI-Zarr header
    # NOTE: we use nifti2 because dimensions typically do not fit in a short
    # TODO: we do not write the json zattrs, but it should be added in
    #       once the nifti-zarr package is released
    shape = list(reversed(omz["0"].shape))
    if has_channel:
        shape = shape[:3] + [1] + shape[3:]
    affine = orientation_to_affine(orientation, vxw, vxh, thickness or 1)
    if center:
        affine = center_affine(affine, shape[:2])
    header = nib.Nifti2Header()
    header.set_data_shape(shape)
    header.set_data_dtype(omz["0"].dtype)
    header.set_qform(affine)
    header.set_sform(affine)
    header.set_xyzt_units(nib.nifti1.unit_codes.code["micron"])
    header.structarr["magic"] = b"n+2\0"
    omz.write_nifti_header(header)

    # Write sidecar .json file
    json_name = os.path.splitext(zarr_config.out)[0]
    json_name += ".json"
    dic = {}
    dic["PixelSize"] = json.dumps([vxw, vxh])
    dic["PixelSizeUnits"] = "um"
    dic["SliceThickness"] = 1.2
    dic["SliceThicknessUnits"] = "mm"
    dic["SampleStaining"] = "LY"

    with open(json_name, "w") as outfile:
        json.dump(dic, outfile)
        outfile.write("\n")

    print("done.")
