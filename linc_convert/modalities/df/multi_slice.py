"""
Convert JPEG2000 files generated by MBF-Neurolucida into a OME-ZARR pyramid.

We do not recompute the image pyramid but instead reuse the JPEG2000
levels (obtained by wavelet transform).
"""

# stdlib
import json
import logging
import os
from typing import Unpack

# externals
import glymur
import nibabel as nib
import numpy as np
from cyclopts import App

# internals
from linc_convert.modalities.df.cli import df
from linc_convert.utils.io.j2k import WrappedJ2K, get_pixelsize
from linc_convert.utils.io.zarr import from_config
from linc_convert.utils.math import ceildiv, floordiv
from linc_convert.utils.nifti_header import build_nifti_header
from linc_convert.utils.orientation import center_affine, orientation_to_affine
from linc_convert.utils.zarr_config import (GeneralConfig, NiiConfig, ZarrConfig,
                                            autoconfig)

# Path to LincBrain dataset
HOME = "/space/aspasia/2/users/linc/000003"
LINCSET = os.path.join(HOME, "sourcedata")
LINCOUT = os.path.join(HOME, "rawdata")

logger = logging.getLogger(__name__)
ms = App(name="multislice", help_format="markdown")
df.command(ms)


@ms.default
@autoconfig
def convert(
    inp: list[str],
    *,
    thickness: float | None = None,
    general_config: GeneralConfig = None,
    zarr_config: ZarrConfig = None,
    nii_config: NiiConfig = None,
) -> None:
    """
    Convert JPEG2000 files generated by MBF-Neurolucida into a Zarr pyramid.

    It does not recompute the image pyramid but instead reuse the
    JPEG2000 levels (obtained by wavelet transform).

    This command converts a batch of slices and stacks them together
    into a single 3D Zarr.


    Parameters
    ----------
    inp
        Path to the input slices
    thickness
        Slice thickness
    general_config
        General configuration
    zarr_config
        Zarr related configuration
    nii_config
        NIfTI header related configuration

    """
    general_config.set_default_name(os.path.splitext(inp[0])[0])
    max_load = general_config.max_load
    omz = from_config(general_config.out, zarr_config)

    nblevel, has_channel, dtype_jp2 = float("inf"), float("inf"), ""

    # Compute output shape
    new_height, new_width = 0, 0
    for inp1 in inp:
        jp2 = glymur.Jp2k(inp1)
        nblevel = min(nblevel, jp2.codestream.segment[2].num_res)
        has_channel = min(has_channel, jp2.ndim - 2)
        dtype_jp2 = np.dtype(jp2.dtype).str
        if jp2.shape[0] > new_height:
            new_height = jp2.shape[0]
        if jp2.shape[1] > new_width:
            new_width = jp2.shape[1]
    new_size = (new_height, new_width)
    if has_channel:
        new_size += (3,)
    print(len(inp), new_size, nblevel, has_channel)
    chunks = list(new_size[2:]) + [1] + list(zarr_config.chunk[-2:])
    zarr_config.chunk = tuple(chunks)
    print(new_size)
    # Write each level
    for level in range(nblevel):
        shape = [ceildiv(s, 2 ** level) for s in new_size[:2]]
        shape = [new_size[2]] + [len(inp)] + shape

        # omz.create_dataset(f"{level}", shape=shape, **opt)
        omz.create_array(str(level), shape, dtype=dtype_jp2, zarr_config=zarr_config)
        array = omz[f"{level}"]

        # Write each slice
        for idx, inp1 in enumerate(inp):
            j2k = glymur.Jp2k(inp1)
            vxw, vxh = get_pixelsize(j2k)
            subdat = WrappedJ2K(j2k, level=level)
            subdat_size = subdat.shape
            print(
                "Convert level",
                level,
                "with shape",
                shape,
                "for slice",
                idx,
                "with size",
                subdat_size,
            )

            # offset while attaching
            x = floordiv(shape[-2] - subdat_size[-2], 2)
            y = floordiv(shape[-1] - subdat_size[-1], 2)

            for channel in range(3):
                if max_load is None or (
                    subdat_size[-2] < max_load and subdat_size[-1] < max_load
                ):
                    array[
                    channel, idx, x: x + subdat_size[-2], y: y + subdat_size[-1]
                    ] = subdat[channel: channel + 1, ...][0]
                else:
                    ni = ceildiv(subdat_size[-2], max_load)
                    nj = ceildiv(subdat_size[-1], max_load)

                    for i in range(ni):
                        for j in range(nj):
                            print(f"\r{i + 1}/{ni}, {j + 1}/{nj}", end=" ")
                            start_x, end_x = (
                                i * max_load,
                                min((i + 1) * max_load, subdat_size[-2]),
                            )
                            start_y, end_y = (
                                j * max_load,
                                min((j + 1) * max_load, subdat_size[-1]),
                            )

                            array[
                            channel,
                            idx,
                            x + start_x: x + end_x,
                            y + start_y: y + end_y,
                            ] = subdat[
                                channel: channel + 1,
                                start_x:end_x,
                                start_y:end_y,
                                ][0]

                    print("")

    # Write OME-Zarr multiscale metadata
    print("Write metadata")
    axes = ["z", "y", "x"]
    if has_channel:
        axes.insert(0, "c")
    omz.write_ome_metadata(
        axes=axes,
        space_scale=[1.0] + list(get_pixelsize(j2k)),
        multiscales_type="jpeg2000",
        no_pool=0,
    )

    # Write NIfTI-Zarr header
    if nii_config.nii:
        header = build_nifti_header(
            zgroup=omz,
            voxel_size_zyx=tuple([vxw, vxh, thickness or 1]),
            unit="micrometer",
            nii_config=nii_config,
        )
        omz.write_nifti_header(header)


    # Write sidecar .json file
    json_name = os.path.splitext(general_config.out)[0]
    json_name += ".json"
    dic = {}
    dic["PixelSize"] = json.dumps([vxw, vxh])
    dic["PixelSizeUnits"] = "um"
    dic["SliceThickness"] = 1.2
    dic["SliceThicknessUnits"] = "mm"
    dic["SampleStaining"] = "LY"

    with open(json_name, "w") as outfile:
        json.dump(dic, outfile)
        outfile.write("\n")

    logger.info("Conversion complete.")
