"""
Matlab to OME-Zarr.

Converts Matlab files generated by the MGH in-house OCT pipeline
into a OME-ZARR pyramid.
"""

import ast
import json
import math
import os
from contextlib import contextmanager
from functools import wraps
from itertools import product
from typing import Callable, Optional
from warnings import warn

import cyclopts
import h5py
import numpy as np
import zarr
from scipy.io import loadmat

from linc_convert.modalities.psoct._utils import (
    generate_pyramid,
    make_json,
    niftizarr_write_header,
    write_ome_metadata,
)
from linc_convert.modalities.psoct.cli import psoct
from linc_convert.utils.math import ceildiv
from linc_convert.utils.orientation import center_affine, orientation_to_affine
from linc_convert.utils.unit import to_nifti_unit, to_ome_unit
from linc_convert.utils.zarr import make_compressor

single_volume = cyclopts.App(name="single_volume", help_format="markdown")
psoct.command(single_volume)


def _automap(func: Callable) -> Callable:
    """Automatically map the array in the mat file."""

    @wraps(func)
    def wrapper(inp: str, out: str = None, **kwargs: dict) -> None:
        if out is None:
            out = os.path.splitext(inp[0])[0]
            out += ".nii.zarr" if kwargs.get("nii", False) else ".ome.zarr"
        kwargs["nii"] = kwargs.get("nii", False) or out.endswith(".nii.zarr")
        with _mapmat(inp, kwargs.get("key", None)) as dat:
            return func(dat, out, **kwargs)

    return wrapper


@contextmanager
def _mapmat(fname: str, key: str = None) -> None:
    """Load or memory-map an array stored in a .mat file."""
    try:
        # "New" .mat file
        f = h5py.File(fname, "r")
    except Exception:
        # "Old" .mat file
        f = loadmat(fname)

    if key is None:
        if not len(f.keys()):
            raise Exception(f"{fname} is empty")
        for key in f.keys():
            if key[:1] != "_":
                break
        if len(f.keys()) > 1:
            warn(
                f"More than one key in .mat file {fname}, "
                f'arbitrarily loading "{key}"'
            )

    if key not in f.keys():
        raise Exception(f"Key {key} not found in file {fname}")

    yield f.get(key)
    if hasattr(f, "close"):
        f.close()


@single_volume.default
@_automap
def convert(
    inp: str,
    out: Optional[str] = None,
    *,
    key: Optional[str] = None,
    meta: str = None,
    chunk: int = 128,
    compressor: str = "blosc",
    compressor_opt: str = "{}",
    max_load: int = 128,
    max_levels: int = 5,
    no_pool: Optional[int] = None,
    nii: bool = False,
    orientation: str = "RAS",
    center: bool = True,
) -> None:
    """
    Matlab to OME-Zarr.

    Convert OCT volumes in raw matlab files
    into a pyramidal OME-ZARR (or NIfTI-Zarr) hierarchy.

    Parameters
    ----------
    inp
        Path to the input mat file
    out
        Path to the output Zarr directory [<INP>.ome.zarr]
    key
        Key of the array to be extracted, default to first key found
    meta
        Path to the metadata file
    chunk
        Output chunk size
    compressor : {blosc, zlib, raw}
        Compression method
    compressor_opt
        Compression options
    max_load
        Maximum input chunk size
    max_levels
        Maximum number of pyramid levels
    no_pool
        Index of dimension to not pool when building pyramid
    nii
        Convert to nifti-zarr. True if path ends in ".nii.zarr"
    orientation
        Orientation of the volume
    center
        Set RAS[0, 0, 0] at FOV center
    """
    if isinstance(compressor_opt, str):
        compressor_opt = ast.literal_eval(compressor_opt)

    # Write OME-Zarr multiscale metadata
    if meta:
        print("Write JSON")
        with open(meta, "r") as f:
            meta_txt = f.read()
            meta_json = make_json(meta_txt)
        path_json = ".".join(out.split(".")[:-2]) + ".json"
        with open(path_json, "w") as f:
            json.dump(meta_json, f, indent=4)
        vx = meta_json["PixelSize"]
        unit = meta_json["PixelSizeUnits"]
    else:
        vx = [1] * 3
        unit = "um"

    # Prepare Zarr group
    omz = zarr.storage.DirectoryStore(out)
    omz = zarr.group(store=omz, overwrite=True)

    if not hasattr(inp, "dtype"):
        raise Exception("Input is not a numpy array. This is unexpected.")
    if len(inp.shape) < 3:
        raise Exception("Input array is not 3d:", inp.shape)
    # Prepare chunking options
    opt = {
        "dimension_separator": r"/",
        "order": "F",
        "dtype": np.dtype(inp.dtype).str,
        "fill_value": None,
        "compressor": make_compressor(compressor, **compressor_opt),
    }

    inp_chunk = [min(x, max_load) for x in inp.shape]
    nk = ceildiv(inp.shape[0], inp_chunk[0])
    nj = ceildiv(inp.shape[1], inp_chunk[1])
    ni = ceildiv(inp.shape[2], inp_chunk[2])

    nblevels = min(
        [int(math.ceil(math.log2(x))) for i, x in enumerate(inp.shape) if i != no_pool]
    )
    nblevels = min(nblevels, int(math.ceil(math.log2(max_load))))
    nblevels = min(nblevels, max_levels)

    opt["chunks"] = [min(x, chunk) for x in inp.shape]

    omz.create_dataset(str(0), shape=inp.shape, **opt)

    # iterate across input chunks
    for i, j, k in product(range(ni), range(nj), range(nk)):
        loaded_chunk = inp[
            k * inp_chunk[0] : (k + 1) * inp_chunk[0],
            j * inp_chunk[1] : (j + 1) * inp_chunk[1],
            i * inp_chunk[2] : (i + 1) * inp_chunk[2],
        ]

        print(
            f"[{i + 1:03d}, {j + 1:03d}, {k + 1:03d}]",
            "/",
            f"[{ni:03d}, {nj:03d}, {nk:03d}]",
            # f"({1 + level}/{nblevels})",
            end="\r",
        )

        # save current chunk
        omz["0"][
            k * inp_chunk[0] : k * inp_chunk[0] + loaded_chunk.shape[0],
            j * inp_chunk[1] : j * inp_chunk[1] + loaded_chunk.shape[1],
            i * inp_chunk[2] : i * inp_chunk[2] + loaded_chunk.shape[2],
        ] = loaded_chunk

    generate_pyramid(omz, nblevels - 1, mode="mean", no_pyramid_axis=no_pool)

    print("")

    # Write OME-Zarr multiscale metadata
    print("Write metadata")
    print(unit)
    ome_unit = to_ome_unit(unit)
    write_ome_metadata(
        omz,
        axes=["z", "y", "x"],
        no_pool=no_pool,
        space_unit=ome_unit,
        space_scale=vx,
        multiscales_type=(("2x2x2" if no_pool is None else "2x2") + "mean window"),
    )

    if not nii:
        print("done.")
        return

    # Write NIfTI-Zarr header
    # NOTE: we use nifti2 because dimensions typically do not fit in a short
    # TODO: we do not write the json zattrs, but it should be added in
    #       once the nifti-zarr package is released
    shape = list(reversed(omz["0"].shape))
    affine = orientation_to_affine(orientation, *vx[::-1])
    if center:
        affine = center_affine(affine, shape[:3])
    niftizarr_write_header(
        omz, shape, affine, omz["0"].dtype, to_nifti_unit(unit), nifti_version=2
    )
