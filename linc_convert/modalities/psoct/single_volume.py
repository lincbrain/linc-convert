"""
Matlab to OME-Zarr.

Converts Matlab files generated by the MGH in-house OCT pipeline
into a OME-ZARR pyramid.
"""

import json
import logging
import os
from typing import Optional

import cyclopts
import numpy as np

from linc_convert.modalities.psoct._utils import make_json
from linc_convert.modalities.psoct.cli import psoct
from linc_convert.utils.chunk_processing import chunk_slice_generator
from linc_convert.utils.io.matlab_array_wrapper import as_arraywrapper
from linc_convert.utils.io.zarr import from_config
from linc_convert.utils.nifti_header import build_nifti_header
from linc_convert.utils.unit import to_ome_unit
from linc_convert.utils.zarr_config import (
    GeneralConfig,
    NiftiConfig,
    ZarrConfig,
    autoconfig,
)

logger = logging.getLogger(__name__)
single_volume = cyclopts.App(name="single_volume", help_format="markdown")
psoct.command(single_volume)


@single_volume.default
@autoconfig
def convert(
    inp: str,
    *,
    key: Optional[str] = None,
    meta: str = None,
    general_config: GeneralConfig = None,
    zarr_config: ZarrConfig = None,
    nii_config: NiftiConfig = None,
) -> None:
    """
    Matlab to OME-Zarr.

    Convert OCT volumes in raw matlab files
    into a pyramidal OME-ZARR (or NIfTI-Zarr) hierarchy.

    Parameters
    ----------
    inp
        Path to the input mat file
    key
        Key of the array to be extracted, default to first key found
    meta
        Path to the metadata file
    general_config
        General configuration
    zarr_config
        Zarr related configuration
    nii_config
        NIfTI header related configuration
    """
    inp = as_arraywrapper(inp, key)
    general_config.set_default_name(os.path.splitext(inp.file)[0])

    out = general_config.out
    # Process metadata if provided
    if meta:
        logger.info("Writing JSON metadata")
        with open(meta, "r") as f:
            meta_txt = f.read()
            meta_json = make_json(meta_txt)
        path_json = ".".join(out.split(".")[:-2]) + ".json"
        with open(path_json, "w") as f:
            json.dump(meta_json, f, indent=4)
        vx = meta_json["PixelSize"]
        unit = meta_json["PixelSizeUnits"]
    else:
        vx = [1, 1, 1]
        unit = "um"

    # Prepare Zarr group
    zgroup = from_config(out, zarr_config)

    if not hasattr(inp, "dtype"):
        raise Exception("Input is not a numpy array. This is unexpected.")
    if len(inp.shape) != 3:
        raise Exception("Input array is not 3d:", inp.shape)

    inp_chunk = [min(x, general_config.max_load) for x in inp.shape]

    dataset = zgroup.create_array(
        "0", shape=inp.shape, dtype=np.dtype(inp.dtype), zarr_config=zarr_config
    )

    for idx, slc in chunk_slice_generator(inp.shape, inp_chunk):
        logger.info(
            f"Processing chunk {idx} of "  # [{nx:03d}, {ny:03d}, {nz:03d}]
        )
        loaded_chunk = inp[slc]
        dataset[slc] = loaded_chunk

    zgroup.generate_pyramid(mode="mean", no_pyramid_axis=zarr_config.no_pyramid_axis)
    logger.info("Write OME-Zarr multiscale metadata")
    zgroup.write_ome_metadata(axes=["z", "y", "x"], space_unit=to_ome_unit(unit))

    if nii_config.nii:
        header = build_nifti_header(
            zgroup=zgroup,
            voxel_size_zyx=tuple(vx),
            unit=unit,
            nii_config=nii_config,
        )
        zgroup.write_nifti_header(header)

    logger.info("Conversion complete.")
