"""
Matlab to OME-Zarr.

Converts Matlab files generated by the MGH in-house OCT pipeline
into a OME-ZARR pyramid.
"""

import json
import logging
import os
from functools import wraps
from itertools import product
from typing import Callable, Optional

import cyclopts
import h5py
import numpy as np

from linc_convert.modalities.psoct._utils import make_json
from linc_convert.modalities.psoct.cli import psoct
from linc_convert.utils.io.matlab import as_arraywrapper
from linc_convert.utils.io.matlab_array_wrapper import (
    ArrayWrapper,
    H5ArrayWrapper,
    MatArraywrapper,
)
from linc_convert.utils.io.zarr import from_config
from linc_convert.utils.math import ceildiv
from linc_convert.utils.nifti_header import build_nifti_header
from linc_convert.utils.unit import to_ome_unit
from linc_convert.utils.zarr_config import (
    GeneralConfig,
    NiiConfig,
    ZarrConfig,
    autoconfig,
)

logger = logging.getLogger(__name__)
multi_slice = cyclopts.App(name="multi_slice", help_format="markdown")
psoct.command(multi_slice)


def _automap(func: Callable) -> Callable:
    """Automatically maps the array in the mat file."""

    @wraps(func)
    def wrapper(inp: list[str], **kwargs: dict) -> callable:
        dat = _mapmat(inp, kwargs.get("key", None))
        return func(dat, **kwargs)

    return wrapper


def _mapmat(fnames: list[str], key: Optional[str] = None) -> list[ArrayWrapper]:
    """Load or memory-map an array stored in a .mat file."""

    def make_wrapper(fname: str) -> ArrayWrapper:
        try:
            # "New" .mat file
            f = h5py.File(fname, "r")
            return H5ArrayWrapper(f, key)
        except Exception:
            # "Old" .mat file
            return MatArraywrapper(fname, key)

    return [make_wrapper(fname) for fname in fnames]


@multi_slice.default
@autoconfig
def convert(
    inp: list[str],
    *,
    key: Optional[str] = None,
    meta: str = None,
    dtype: Optional[str] = None,
    general_config: GeneralConfig = None,
    zarr_config: ZarrConfig = None,
    nii_config: NiiConfig = None,
) -> None:
    """
    Matlab to OME-Zarr.

    Convert OCT volumes in raw matlab files into a pyramidal
    OME-ZARR (or NIfTI-Zarr) hierarchy.

    This command assumes that each slice in a volume is stored in a
    different mat file. All slices must have the same shape and will be
    concatenated into a 3D Zarr.

    Parameters
    ----------
    inp : list of str
        Paths to the input mat files.
    key : Optional[str]
        Key of the array to be extracted; defaults to the first key found.
    meta : str
        Path to the metadata file.
    dtype : Optional[str]
        Data type to write into.
    general_config
        General configuration
    zarr_config
        Zarr related configuration
    nii_config
        NIfTI header related configuration
    """
    inp = [as_arraywrapper(i, key) for i in inp]
    general_config.set_default_name(os.path.splitext(inp[0].file)[0])
    # Process metadata if provided
    if meta:
        logger.info("Writing JSON metadata")
        with open(meta, "r") as f:
            meta_txt = f.read()
            meta_json = make_json(meta_txt)
        path_json = ".".join(zarr_config.out.split(".")[:-2]) + ".json"
        with open(path_json, "w") as f:
            json.dump(meta_json, f, indent=4)
        vx = meta_json["PixelSize"]
        unit = meta_json["PixelSizeUnits"]
    else:
        vx = [1, 1, 1]
        unit = "um"

    # Prepare Zarr group
    zgroup = from_config(general_config.out, zarr_config)

    if not hasattr(inp[0], "dtype"):
        raise Exception("Input is not an array. This is likely unexpected")
    if len(inp[0].shape) != 2:
        raise ValueError(f"Input array is not 2D: {inp[0].shape}")

    dtype = dtype or np.dtype(inp[0].dtype).str
    # The overall volume shape: (slice height, slice width, number of slices)
    volume_shape = (*inp[0].shape, len(inp))
    # Use the entire dimensions as chunk sizes (replace with max_load if needed)
    chunk_size = list(volume_shape[-3:])
    nz = ceildiv(volume_shape[-3], chunk_size[0])
    ny = ceildiv(volume_shape[-2], chunk_size[1])
    nslices = len(inp)

    dataset = zgroup.create_array(
        "0", shape=volume_shape, zarr_config=zarr_config, dtype=np.dtype(dtype)
    )

    # Process and store data in chunks
    for i in range(nslices):
        for j, k in product(range(ny), range(nz)):
            loaded_chunk = inp[i][
                           ...,
                           k * chunk_size[0]: (k + 1) * chunk_size[0],
                           j * chunk_size[1]: (j + 1) * chunk_size[1],
                           ]
            logger.info(
                f"Processing slice {i + 1:03d} chunk [y: {j + 1:03d}, z: "
                f"{k + 1:03d}] "
                f"of [{nslices:03d}, {ny:03d}, {nz:03d}]"
            )
            z_start = k * chunk_size[0]
            z_end = z_start + loaded_chunk.shape[-2]
            y_start = j * chunk_size[1]
            y_end = y_start + loaded_chunk.shape[-1]
            dataset[
            ...,
            z_start:z_end,
            y_start:y_end,
            i,
            ] = loaded_chunk
        inp[i] = None  # Remove reference to free memory

    zgroup.generate_pyramid(mode="mean", no_pyramid_axis=zarr_config.no_pyramid_axis)
    logger.info("Write OME-Zarr multiscale metadata")
    zgroup.write_ome_metadata(axes=["z", "y", "x"], space_unit=to_ome_unit(unit))

    if nii_config.nii:
        header = build_nifti_header(
            zgroup=zgroup,
            voxel_size_zyx=tuple(vx),
            unit=unit,
            nii_config=nii_config,
        )
        zgroup.write_nifti_header(header)

    logger.info("Conversion complete.")
