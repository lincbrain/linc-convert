"""
Matlab to OME-Zarr.

Converts Matlab files generated by the MGH in-house OCT pipeline
into a OME-ZARR pyramid.
"""

import json
import logging
import os
from functools import wraps
from itertools import product
from typing import Callable, Optional, Unpack

import cyclopts
import h5py
import numpy as np
from niizarr import default_nifti_header

from linc_convert.modalities.psoct._utils import make_json
from linc_convert.modalities.psoct.cli import psoct
from linc_convert.utils.io._array_wrapper import (
    _ArrayWrapper,
    _H5ArrayWrapper,
    _MatArrayWrapper,
)
from linc_convert.utils.io.zarr import from_config
from linc_convert.utils.math import ceildiv
from linc_convert.utils.orientation import center_affine, orientation_to_affine
from linc_convert.utils.unit import to_nifti_unit, to_ome_unit
from linc_convert.utils.zarr_config import ZarrConfig, update_default_config

logger = logging.getLogger(__name__)
multi_slice = cyclopts.App(name="multi_slice", help_format="markdown")
psoct.command(multi_slice)


def _automap(func: Callable) -> Callable:
    """Automatically maps the array in the mat file."""

    @wraps(func)
    def wrapper(inp: list[str], **kwargs: dict) -> callable:
        dat = _mapmat(inp, kwargs.get("key", None))
        return func(dat, **kwargs)

    return wrapper


def _mapmat(fnames: list[str], key: Optional[str] = None) -> list[_ArrayWrapper]:
    """Load or memory-map an array stored in a .mat file."""

    def make_wrapper(fname: str) -> _ArrayWrapper:
        try:
            # "New" .mat file
            f = h5py.File(fname, "r")
            return _H5ArrayWrapper(f, key)
        except Exception:
            # "Old" .mat file
            return _MatArrayWrapper(fname, key)

    return [make_wrapper(fname) for fname in fnames]


@multi_slice.default
@_automap
def convert(
    inp: list[str],
    *,
    key: Optional[str] = None,
    meta: str = None,
    orientation: str = "RAS",
    center: bool = True,
    dtype: Optional[str] = None,
    zarr_config: ZarrConfig = None,
    **kwargs: Unpack[ZarrConfig],
) -> None:
    """
    Matlab to OME-Zarr.

    Convert OCT volumes in raw matlab files into a pyramidal
    OME-ZARR (or NIfTI-Zarr) hierarchy.

    This command assumes that each slice in a volume is stored in a
    different mat file. All slices must have the same shape and will be
    concatenated into a 3D Zarr.

    Parameters
    ----------
    inp : list of str
        Paths to the input mat files.
    key : Optional[str]
        Key of the array to be extracted; defaults to the first key found.
    meta : str
        Path to the metadata file.
    orientation : str
        Orientation of the volume.
    center : bool
        Set RAS[0, 0, 0] at FOV center.
    dtype : Optional[str]
        Data type to write into.
    """
    zarr_config = update_default_config(zarr_config, **kwargs)
    zarr_config.set_default_name(os.path.splitext(inp[0].file)[0])

    # Process metadata if provided
    if meta:
        logger.info("Writing JSON metadata")
        with open(meta, "r") as f:
            meta_txt = f.read()
            meta_json = make_json(meta_txt)
        path_json = ".".join(zarr_config.out.split(".")[:-2]) + ".json"
        with open(path_json, "w") as f:
            json.dump(meta_json, f, indent=4)
        vx = meta_json["PixelSize"]
        unit = meta_json["PixelSizeUnits"]
    else:
        vx = [1, 1, 1]
        unit = "um"

    # Prepare Zarr group
    zgroup = from_config(zarr_config)

    if not hasattr(inp[0], "dtype"):
        raise Exception("Input is not an array. This is likely unexpected")
    if len(inp[0].shape) != 2:
        raise ValueError(f"Input array is not 2D: {inp[0].shape}")

    dtype = dtype or np.dtype(inp[0].dtype).str
    # The overall volume shape: (slice height, slice width, number of slices)
    volume_shape = (*inp[0].shape, len(inp))
    # Use the entire dimensions as chunk sizes (replace with max_load if needed)
    chunk_size = list(volume_shape[-3:])
    nz = ceildiv(volume_shape[-3], chunk_size[0])
    ny = ceildiv(volume_shape[-2], chunk_size[1])
    nslices = len(inp)

    dataset = zgroup.create_array(
        "0", shape=volume_shape, zarr_config=zarr_config, dtype=np.dtype(dtype)
    )

    # Process and store data in chunks
    for i in range(nslices):
        for j, k in product(range(ny), range(nz)):
            loaded_chunk = inp[i][
                           ...,
                           k * chunk_size[0]: (k + 1) * chunk_size[0],
                           j * chunk_size[1]: (j + 1) * chunk_size[1],
                           ]
            logger.info(
                f"Processing slice {i + 1:03d} chunk [y: {j + 1:03d}, z: "
                f"{k + 1:03d}] "
                f"of [{nslices:03d}, {ny:03d}, {nz:03d}]"
            )
            z_start = k * chunk_size[0]
            z_end = z_start + loaded_chunk.shape[-2]
            y_start = j * chunk_size[1]
            y_end = y_start + loaded_chunk.shape[-1]
            dataset[
            ...,
            z_start:z_end,
            y_start:y_end,
            i,
            ] = loaded_chunk
        inp[i] = None  # Remove reference to free memory

    zgroup.generate_pyramid(mode="mean", no_pyramid_axis=zarr_config.no_pyramid_axis)
    logger.info("Write OME-Zarr multiscale metadata")
    zgroup.write_ome_metadata(axes=["z", "y", "x"], space_unit=to_ome_unit(unit))

    if not zarr_config.nii:
        logger.info("Conversion complete.")
        return

    # Write NIfTI-Zarr header
    arr = zgroup["0"]
    header = default_nifti_header(
        arr, zgroup.attrs.get("ome", zgroup.attrs).get("multiscales")
    )
    reversed_shape = list(reversed(arr.shape))
    affine = orientation_to_affine(orientation, *vx[::-1])
    if center:
        affine = center_affine(affine, reversed_shape[:3])
    header.set_data_shape(reversed_shape)
    header.set_data_dtype(arr.dtype)
    header.set_qform(affine)
    header.set_sform(affine)
    header.set_xyzt_units(to_nifti_unit(unit))

    zgroup.write_nifti_header(header)
